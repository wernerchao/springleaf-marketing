{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (8,9,10,11,12,43,157,196,214,225,228,229,231,235,238) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../../data/train.csv')\n",
    "# Drop column with mostly empty values.\n",
    "train = train.drop(['VAR_0205', 'VAR_0206', 'VAR_0207', 'VAR_0208', 'VAR_0209', 'VAR_0213', 'VAR_0840'], 1)\n",
    "# Drop date columns for now...\n",
    "train = train.drop(['VAR_0073', 'VAR_0075', 'VAR_0156', 'VAR_0157', 'VAR_0158', \\\n",
    "                    'VAR_0159', 'VAR_0166', 'VAR_0167', 'VAR_0168', 'VAR_0169', \\\n",
    "                    'VAR_0176', 'VAR_0177', 'VAR_0178', 'VAR_0179', 'VAR_0204', 'VAR_0217'], 1)\n",
    "# Drop ID and target column for now...\n",
    "target = train['target']\n",
    "train = train.drop(['ID', 'target'], 1)\n",
    "# feature = [x for x in train.columns if x not in ['ID', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Columns with binary values.\n",
    "# [VAR_0098, VAR_0106, VAR_0114, VAR_0130, VAR_0138, VAR_0180, VAR_0181, VAR_0182, VAR_0191, VAR_0244, VAR_0247, \\\n",
    "# VAR_0344, VAR_0362, VAR_0383, VAR_0384, VAR_0392, VAR_0395, VAR_0411, VAR_0459, VAR_0468, VAR_0490, VAR_0502, \\\n",
    "# VAR_0503, VAR_0504, VAR_0505, VAR_0526, VAR_0529, VAR_0563, VAR_0566, VAR_0567, VAR_0732, VAR_0733, VAR_0736, \\\n",
    "# VAR_0737, VAR_0739, VAR_0740, VAR_0741, VAR_0924, VAR_1162, VAR_1163, VAR_1164, VAR_1165, VAR_1427]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145231 entries, 0 to 145230\n",
      "Columns: 1909 entries, VAR_0001 to VAR_1934\n",
      "dtypes: float64(470), int64(1404), object(35)\n",
      "memory usage: 2.1+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If 'int64' > 20 unique values then it's probably a numerical feature\n",
    "criteria = train.dtypes == 'int64'\n",
    "int_train = train[criteria.index[criteria]]\n",
    "criteria_num = int_train.apply(lambda x: len(x.unique()) > 20)\n",
    "criteria_cat = int_train.apply(lambda x: len(x.unique()) <= 20)\n",
    "\n",
    "# Making numeric/categorical dataframes from int64\n",
    "int_num_train = int_train[criteria_num.index[criteria_num]]\n",
    "int_cat_train = int_train[criteria_cat.index[criteria_cat]]\n",
    "\n",
    "# print int_train.info()\n",
    "# print '\\n', int_num_train.info()\n",
    "# print '\\n', int_cat_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before concatenating df:  (145231, 470)\n",
      "No. of missing values:  634179\n",
      "After concatenating df:  (145231, 1465)\n",
      "No. of missing values:  0\n"
     ]
    }
   ],
   "source": [
    "# More efficient way to fill in missing values with mean() for numeric features\n",
    "criteria = train.dtypes == 'float64'\n",
    "num_train = train[criteria.index[criteria]]\n",
    "print 'Before concatenating df: ', num_train.shape\n",
    "print 'No. of missing values: ', num_train.isnull().values.sum()\n",
    "\n",
    "num_train = pd.concat([num_train, int_num_train], axis=1)\n",
    "num_train = num_train.fillna(num_train.mean())\n",
    "print 'After concatenating df: ', num_train.shape\n",
    "print 'No. of missing values: ', num_train.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before concatenating df:  (145231, 35)\n",
      "No. of missing values:  157303\n",
      "After concatenating df:  (145231, 444)\n",
      "No. of missing values:  0\n"
     ]
    }
   ],
   "source": [
    "# More efficient way to fill in missing values with most frequent value for categorical features\n",
    "criteria = train.dtypes == 'object'\n",
    "cat_train = train[criteria.index[criteria]]\n",
    "print 'Before concatenating df: ', cat_train.shape\n",
    "print 'No. of missing values: ', cat_train.isnull().values.sum()\n",
    "\n",
    "cat_train = pd.concat([cat_train, int_cat_train], axis=1)\n",
    "cat_train = cat_train.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "print 'After concatenating df: ', cat_train.shape\n",
    "print 'No. of missing values: ', cat_train.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for the categorical features.\n",
    "cat_train = pd.get_dummies(data=cat_train)\n",
    "print cat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (145231, 16925)\n",
      "After:  (145231, 16925)\n"
     ]
    }
   ],
   "source": [
    "print 'Before: ', train.shape\n",
    "train = pd.concat([num_train, cat_train], axis=1)\n",
    "print 'After: ', train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the unique values in each categorical feature.\n",
    "# print cat_train.unique()\n",
    "\n",
    "# TODO: Delete\n",
    "# for i, column in enumerate(cat_feat):\n",
    "#     print train[column].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 20building tree 2 of 20\n",
      "\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  20 out of  20 | elapsed:   36.4s finished\n",
      "[Parallel(n_jobs=2)]: Done  20 out of  20 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.573449905512\n",
      "[  4.86954682e-04   4.62719034e-04   1.16883287e-03 ...,   3.98752523e-04\n",
      "   1.16863401e-04   6.41440296e-05]\n"
     ]
    }
   ],
   "source": [
    "# Do a random forest quick check with 1 hold-out test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, target, test_size=0.25, random_state=42)\n",
    "rf_2 = RandomForestClassifier(n_estimators=20, verbose=2, n_jobs=2)\n",
    "rf_2.fit(x_train, y_train)\n",
    "rf_2_pred = rf_2.predict(x_test)\n",
    "scoring = roc_auc_score(y_test, rf_2_pred)\n",
    "\n",
    "print scoring\n",
    "print rf_2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    }
   ],
   "source": [
    "### TODO: Maybe remove because cannot run efficiently. Do a randomforest quick check. Not efficient.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "rf_cv = cross_val_score(rf, train, target, scoring='roc_auc', cv=3, n_jobs=2, verbose=3)\n",
    "print 'Random Forest CV score: ', rf_cv\n",
    "print 'Random Forest CV score mean: ', rf_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
